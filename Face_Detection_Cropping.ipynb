{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npip install opencv-python\\npython -m pip install --user opencv-contrib-python\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Sources:\n",
    "http://opencv.willowgarage.com/documentation/python/cookbook.html\n",
    "http://www.lucaamore.com/?p=638\n",
    "'''\n",
    "\n",
    "#Python 2.7.2\n",
    "#Opencv 2.4.2\n",
    "#PIL 1.1.7\n",
    "\n",
    "\n",
    "import cv2 as cv\n",
    "from PIL import Image #Image from PIL\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "pip install opencv-python\n",
    "python -m pip install --user opencv-contrib-python\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DetectFace(image, faceCascade, returnImage=False):\n",
    "    # This function takes a grey scale cv image and finds\n",
    "    # the patterns defined in the haarcascade function\n",
    "    # modified from: http://www.lucaamore.com/?p=638\n",
    "\n",
    "    #variables    \n",
    "    min_size = (20,20)\n",
    "    haar_scale = 1.1\n",
    "    min_neighbors = 3\n",
    "    haar_flags = 0\n",
    "\n",
    "    # Equalize the histogram\n",
    "    #cv.EqualizeHist(image, image)\n",
    "    image=cv.equalizeHist(image)\n",
    "\n",
    "    # Detect the faces\n",
    "    faces = cv.haarDetectObjects(\n",
    "            image, faceCascade, cv.CreateMemStorage(0),\n",
    "            haar_scale, min_neighbors, haar_flags, min_size\n",
    "        )\n",
    "\n",
    "    # If faces are found\n",
    "    if faces and returnImage:\n",
    "        for ((x, y, w, h), n) in faces:\n",
    "            # Convert bounding box to two CvPoints\n",
    "            pt1 = (int(x), int(y))\n",
    "            pt2 = (int(x + w), int(y + h))\n",
    "            cv.Rectangle(image, pt1, pt2, cv.RGB(255, 0, 0), 5, 8, 0)\n",
    "\n",
    "    if returnImage:\n",
    "        return image\n",
    "    else:\n",
    "        return faces\n",
    "\n",
    "def pil2cvGrey(pil_im):\n",
    "    # Convert a PIL image to a greyscale cv image\n",
    "    # from: http://pythonpath.wordpress.com/2012/05/08/pil-to-opencv-image/\n",
    "    pil_im = pil_im.convert('L')\n",
    "    cv_im = cv.CreateImageHeader(pil_im.size, cv.IPL_DEPTH_8U, 1)\n",
    "    cv.SetData(cv_im, pil_im.tostring(), pil_im.size[0]  )\n",
    "    return cv_im\n",
    "\n",
    "def cv2pil(cv_im):\n",
    "    # Convert the cv image to a PIL image\n",
    "    return Image.fromstring(\"L\", cv.GetSize(cv_im), cv_im.tostring())\n",
    "\n",
    "def imgCrop(image, cropBox, boxScale=1):\n",
    "    # Crop a PIL image with the provided box [x(left), y(upper), w(width), h(height)]\n",
    "\n",
    "    # Calculate scale factors\n",
    "    xDelta=max(cropBox[2]*(boxScale-1),0)\n",
    "    yDelta=max(cropBox[3]*(boxScale-1),0)\n",
    "\n",
    "    # Convert cv box to PIL box [left, upper, right, lower]\n",
    "    PIL_box=[cropBox[0]-xDelta, cropBox[1]-yDelta, cropBox[0]+cropBox[2]+xDelta, cropBox[1]+cropBox[3]+yDelta]\n",
    "\n",
    "    return image.crop(PIL_box)\n",
    "\n",
    "def faceCrop(imagePattern,boxScale=1):\n",
    "    # Select one of the haarcascade files:\n",
    "    #   haarcascade_frontalface_alt.xml  <-- Best one?\n",
    "    #   haarcascade_frontalface_alt2.xml\n",
    "    #   haarcascade_frontalface_alt_tree.xml\n",
    "    #   haarcascade_frontalface_default.xml\n",
    "    #   haarcascade_profileface.xml\n",
    "    #faceCascade = cv.Load('haarcascade_frontalface_alt.xml')\n",
    "    #faceCascade = cv.CascadeClassifier('/usr/share/OpenCV/haarcascades/haarcascade_frontalface_alt2.xml')\n",
    "    faceCascade = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "    imgList=glob.glob(imagePattern)\n",
    "    if len(imgList)<=0:\n",
    "        print('No Images Found')\n",
    "        return\n",
    "\n",
    "    for img in imgList:\n",
    "        \n",
    "        #pil_im=Image.open(img)\n",
    "        #cv_im=pil2cvGrey(pil_im)\n",
    "        \n",
    "        image= cv2.imread(img)\n",
    "        cv_im = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        \n",
    "        \n",
    "        faces=DetectFace(cv_im,faceCascade)\n",
    "        if faces:\n",
    "            n=1\n",
    "            for face in faces:\n",
    "                croppedImage=imgCrop(pil_im, face[0],boxScale=boxScale)\n",
    "                fname,ext=os.path.splitext(img)\n",
    "                croppedImage.save(fname+'_crop'+str(n)+ext)\n",
    "                n+=1\n",
    "        else:\n",
    "            print('No faces found:', img)\n",
    "\n",
    "def test(imageFilePath):\n",
    "    pil_im=Image.open(imageFilePath)\n",
    "    cv_im=pil2cvGrey(pil_im)\n",
    "    # Select one of the haarcascade files:\n",
    "    #   haarcascade_frontalface_alt.xml  <-- Best one?\n",
    "    #   haarcascade_frontalface_alt2.xml\n",
    "    #   haarcascade_frontalface_alt_tree.xml\n",
    "    #   haarcascade_frontalface_default.xml\n",
    "    #   haarcascade_profileface.xml\n",
    "    faceCascade = cv.Load('haarcascade_frontalface_alt.xml')\n",
    "    face_im=DetectFace(cv_im,faceCascade, returnImage=True)\n",
    "    img=cv2pil(face_im)\n",
    "    img.show()\n",
    "    img.save('test.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'HaarDetectObjects'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-de25728ef4af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Crop all jpegs in a folder. Note: the code uses glob which follows unix shell rules.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Use the boxScale to scale the cropping area. 1=opencv box, 2=2x the width and height\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mfaceCrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'testPics/1.jpeg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mboxScale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-d06866fff1d3>\u001b[0m in \u001b[0;36mfaceCrop\u001b[1;34m(imagePattern, boxScale)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mfaces\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDetectFace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_im\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfaceCascade\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-d06866fff1d3>\u001b[0m in \u001b[0;36mDetectFace\u001b[1;34m(image, faceCascade, returnImage)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# Detect the faces\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     faces = cv.HaarDetectObjects(\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfaceCascade\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCreateMemStorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mhaar_scale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_neighbors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhaar_flags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'HaarDetectObjects'"
     ]
    }
   ],
   "source": [
    "# Test the algorithm on an image\n",
    "#test('testPics/faces.jpg')\n",
    "\n",
    "# Crop all jpegs in a folder. Note: the code uses glob which follows unix shell rules.\n",
    "# Use the boxScale to scale the cropping area. 1=opencv box, 2=2x the width and height\n",
    "faceCrop('testPics/1.jpeg',boxScale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
